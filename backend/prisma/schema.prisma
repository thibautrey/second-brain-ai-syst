// Prisma schema for Second Brain AI System Backend

datasource db {
    provider = "postgresql"
    url      = env("DATABASE_URL")
}

generator client {
    provider = "prisma-client-js"
}

// ==================== User Model ====================

model User {
    id       String  @id @default(cuid())
    email    String  @unique
    password String
    name     String?

    createdAt DateTime @default(now())
    updatedAt DateTime @updatedAt

    // Relations
    processedInputs        ProcessedInput[]
    speakerProfiles        SpeakerProfile[]
    audioStreamSessions    AudioStreamSession[]
    audioBatches           AudioBatch[]
    inputProcessingMetrics InputProcessingMetrics[]
    memories               Memory[]
    summaries              Summary[]
    aiProviders            AIProvider[]
    aiTaskConfigs          AITaskConfig[]
    settings               UserSettings?

    @@map("users")
}

// ==================== User Settings Model ====================

model UserSettings {
    id     String @id @default(cuid())
    userId String @unique
    user   User   @relation(fields: [userId], references: [id], onDelete: Cascade)

    // Continuous Listening Settings
    continuousListeningEnabled Boolean @default(false)
    wakeWord                   String  @default("Hey Brain")
    wakeWordSensitivity        Float   @default(0.8) // 0.0 - 1.0
    minImportanceThreshold     Float   @default(0.3) // Seuil pour stockage mémoire passive
    silenceDetectionMs         Int     @default(1500) // Durée silence = fin de phrase

    // Audio Processing Settings
    vadSensitivity              Float   @default(0.5) // 0.0 - 1.0
    speakerConfidenceThreshold  Float   @default(0.7) // Seuil identification speaker
    autoDeleteAudioAfterProcess Boolean @default(true) // Supprimer audio après traitement

    // Notification Settings
    notifyOnMemoryStored    Boolean @default(true)
    notifyOnCommandDetected Boolean @default(true)

    createdAt DateTime @default(now())
    updatedAt DateTime @updatedAt

    @@map("user_settings")
}

// ==================== Memory Models ====================

model Memory {
    id     String @id @default(cuid())
    userId String
    user   User   @relation(fields: [userId], references: [id], onDelete: Cascade)

    // Memory content
    content String @db.Text

    // Memory classification
    type      MemoryType @default(SHORT_TERM)
    timeScale TimeScale?

    // Source tracking
    sourceType    String? // 'interaction', 'observation', 'reflection', 'tool_result'
    sourceId      String? // Reference to source (e.g., ProcessedInput id)
    interactionId String? // Direct link to ProcessedInput if applicable

    // Embedding for semantic search
    embeddingId String? // Reference to vector in Weaviate
    embedding   Json? // Optional: store embedding directly for backup

    // Scoring and organization
    importanceScore Float    @default(0.5) // 0.0 - 1.0
    tags            String[] @default([])
    entities        String[] @default([]) // Named entities extracted

    // Metadata
    metadata Json @default("{}")

    // Temporal context
    occurredAt DateTime? // When the event/interaction happened (if different from creation)

    // Status
    isArchived Boolean @default(false)
    isPinned   Boolean @default(false)

    createdAt DateTime @default(now())
    updatedAt DateTime @updatedAt

    // Relations
    sourceSummaries Summary[] @relation("SourceMemories")

    @@index([userId])
    @@index([type])
    @@index([timeScale])
    @@index([importanceScore])
    @@index([isArchived])
    @@index([createdAt])
    @@map("memories")
}

model Summary {
    id     String @id @default(cuid())
    userId String
    user   User   @relation(fields: [userId], references: [id], onDelete: Cascade)

    // Summary content
    content String  @db.Text
    title   String?

    // Time period covered
    timeScale   TimeScale
    periodStart DateTime
    periodEnd   DateTime

    // Linking to source memories
    sourceMemories    Memory[] @relation("SourceMemories")
    sourceMemoryCount Int      @default(0)

    // Extracted insights
    keyInsights String[] @default([])
    topics      String[] @default([])
    sentiment   String? // 'positive', 'neutral', 'negative', 'mixed'
    actionItems String[] @default([])

    // Embedding for semantic search
    embeddingId String?
    embedding   Json?

    // Metadata
    metadata Json @default("{}")

    // Version tracking (summaries can be regenerated)
    version  Int     @default(1)
    parentId String? // Previous version of this summary

    createdAt DateTime @default(now())
    updatedAt DateTime @updatedAt

    @@index([userId])
    @@index([timeScale])
    @@index([periodStart, periodEnd])
    @@map("summaries")
}

enum MemoryType {
    SHORT_TERM
    LONG_TERM
}

enum TimeScale {
    DAILY
    THREE_DAY
    WEEKLY
    BIWEEKLY
    MONTHLY
    QUARTERLY
    SIX_MONTH
    YEARLY
    MULTI_YEAR
}

// ==================== Input Ingestion Models ====================

model ProcessedInput {
    id     String @id @default(cuid())
    userId String
    user   User   @relation(fields: [userId], references: [id], onDelete: Cascade)

    format          String // 'text', 'audio_stream', 'audio_batch'
    content         String @db.Text
    originalContent Bytes? // Raw audio data if applicable

    speakerId         String
    speakerConfidence Float  @default(1.0) // 0.0 - 1.0
    speakerMethod     String @default("assumed") // 'assumed', 'identified', 'uncertain'

    status          String @default("pending") // 'pending', 'processing', 'completed', 'failed'
    durationSeconds Float?

    metadata     Json      @default("{}")
    errorMessage String?
    retryCount   Int       @default(0)
    processedAt  DateTime?

    createdAt DateTime @default(now())
    updatedAt DateTime @updatedAt

    // Relations
    audioStream     AudioStreamSession?     @relation(fields: [audioStreamId], references: [id], onDelete: SetNull)
    audioStreamId   String?
    batchResults    BatchProcessingResult[]
    metricsSnapshot InputProcessingMetrics? @relation("MetricsSnapshot")

    @@index([userId])
    @@index([status])
    @@map("processed_inputs")
}

model SpeakerProfile {
    id     String @id @default(cuid())
    userId String
    user   User   @relation(fields: [userId], references: [id], onDelete: Cascade)

    name                 String
    voiceCharacteristics Json   @default("{}")
    identificationMethod String @default("manual") // 'manual', 'ml_model', 'confirmed'
    confidence           Float  @default(1.0)

    // Embedding data
    centroidEmbedding Json? // Average of all voice sample embeddings
    embeddingModel    String @default("ecapa-tdnn") // Model used for embeddings
    embeddingVersion  String @default("1.0")

    // Training state
    isEnrolled       Boolean   @default(false) // Has completed initial enrollment
    enrollmentDate   DateTime?
    lastTrainingDate DateTime?

    createdAt DateTime @default(now())
    updatedAt DateTime @updatedAt

    // Relations
    voiceSamples     VoiceSample[]
    trainingSessions TrainingSession[]

    @@index([userId])
    @@map("speaker_profiles")
}

// ==================== Voice Training Models ====================

model VoiceSample {
    id               String         @id @default(cuid())
    speakerProfileId String
    speakerProfile   SpeakerProfile @relation(fields: [speakerProfileId], references: [id], onDelete: Cascade)

    // File storage
    storagePath     String // Local path to audio file
    originalName    String // Original filename
    mimeType        String @default("audio/wav")
    fileSizeBytes   Int
    durationSeconds Float

    // Training phrase info
    phraseText     String? // The phrase that was spoken
    phraseCategory String? // 'passphrase', 'sentence', 'numeric'

    // Embedding data
    embedding      Json? // Vector embedding extracted from this sample
    embeddingModel String? // Model used for this embedding

    // Processing state
    status       String    @default("pending") // 'pending', 'processing', 'completed', 'failed'
    errorMessage String?
    processedAt  DateTime?

    createdAt DateTime @default(now())
    updatedAt DateTime @updatedAt

    @@index([speakerProfileId])
    @@index([status])
    @@map("voice_samples")
}

model TrainingSession {
    id               String         @id @default(cuid())
    speakerProfileId String
    speakerProfile   SpeakerProfile @relation(fields: [speakerProfileId], references: [id], onDelete: Cascade)

    // Training configuration
    modelType     String @default("ecapa-tdnn")
    sampleCount   Int // Number of samples used
    totalDuration Float // Total audio duration in seconds

    // Progress tracking
    status       String  @default("pending") // 'pending', 'processing', 'completed', 'failed'
    progress     Float   @default(0) // 0-100
    currentStep  String? // Current processing step description
    errorMessage String?

    // Results
    centroidEmbedding  Json? // Computed centroid from all samples
    confidenceScore    Float? // Quality/consistency score
    intraClassVariance Float? // Variance between samples (lower = more consistent)

    startedAt   DateTime?
    completedAt DateTime?
    createdAt   DateTime  @default(now())
    updatedAt   DateTime  @updatedAt

    @@index([speakerProfileId])
    @@index([status])
    @@map("training_sessions")
}

model AudioStreamSession {
    id     String @id @default(cuid())
    userId String
    user   User   @relation(fields: [userId], references: [id], onDelete: Cascade)

    sessionName  String
    format       String @default("wav") // 'wav', 'mp3', 'aac', 'flac'
    sampleRate   Int    @default(16000)
    channelCount Int    @default(1)
    duration     Float?

    startedAt   DateTime  @default(now())
    completedAt DateTime?
    status      String    @default("active") // 'active', 'completed', 'error'

    processedInputs ProcessedInput[]
    metadata        Json             @default("{}")

    @@index([userId])
    @@map("audio_stream_sessions")
}

model AudioBatch {
    id     String @id @default(cuid())
    userId String
    user   User   @relation(fields: [userId], references: [id], onDelete: Cascade)

    batchName     String
    fileCount     Int
    totalDuration Float?
    uploadedAt    DateTime  @default(now())
    processedAt   DateTime?
    status        String    @default("pending") // 'pending', 'processing', 'completed', 'error'

    batchResults BatchProcessingResult[]
    metadata     Json                    @default("{}")

    @@index([userId])
    @@index([status])
    @@map("audio_batches")
}

model BatchProcessingResult {
    id      String     @id @default(cuid())
    batchId String
    batch   AudioBatch @relation(fields: [batchId], references: [id], onDelete: Cascade)

    processedInputId String
    processedInput   ProcessedInput @relation(fields: [processedInputId], references: [id], onDelete: Cascade)

    fileIndex      Int
    fileName       String
    processingTime Float?
    success        Boolean @default(true)
    errorMessage   String?

    @@unique([batchId, fileIndex])
    @@map("batch_processing_results")
}

model InputProcessingMetrics {
    id     String @id @default(cuid())
    userId String
    user   User   @relation(fields: [userId], references: [id], onDelete: Cascade)

    snapshotId     String?         @unique
    processedInput ProcessedInput? @relation("MetricsSnapshot", fields: [snapshotId], references: [id], onDelete: SetNull)

    totalInputs           Int
    successfulInputs      Int
    failedInputs          Int
    averageProcessingTime Float?
    lastProcessedAt       DateTime?

    createdAt DateTime @default(now())
    updatedAt DateTime @updatedAt

    @@index([userId])
    @@map("input_processing_metrics")
}

// ==================== AI Settings Models ====================

model AIProvider {
    id     String @id @default(cuid())
    userId String
    user   User   @relation(fields: [userId], references: [id], onDelete: Cascade)

    name      String
    type      ProviderType // 'OPENAI' or 'OPENAI_COMPATIBLE'
    apiKey    String // Encrypted API key
    baseUrl   String? // Required for OPENAI_COMPATIBLE type
    isEnabled Boolean      @default(true)

    createdAt DateTime @default(now())
    updatedAt DateTime @updatedAt

    // Relations
    models      AIModel[]
    taskConfigs AITaskConfig[]

    @@unique([userId, name])
    @@index([userId])
    @@map("ai_providers")
}

model AIModel {
    id         String     @id @default(cuid())
    providerId String
    provider   AIProvider @relation(fields: [providerId], references: [id], onDelete: Cascade)

    modelId      String // The actual model ID (e.g., 'gpt-4o', 'whisper-1')
    name         String // Display name
    capabilities ModelCapability[] // What this model can do
    isCustom     Boolean           @default(false) // User-added vs default

    createdAt DateTime @default(now())
    updatedAt DateTime @updatedAt

    // Relations
    taskConfigs AITaskConfig[]

    @@unique([providerId, modelId])
    @@index([providerId])
    @@map("ai_models")
}

model AITaskConfig {
    id     String @id @default(cuid())
    userId String
    user   User   @relation(fields: [userId], references: [id], onDelete: Cascade)

    taskType   ModelCapability @unique // One config per task type per user
    providerId String?
    provider   AIProvider?     @relation(fields: [providerId], references: [id], onDelete: SetNull)
    modelId    String?
    model      AIModel?        @relation(fields: [modelId], references: [id], onDelete: SetNull)

    createdAt DateTime @default(now())
    updatedAt DateTime @updatedAt

    @@unique([userId, taskType])
    @@index([userId])
    @@map("ai_task_configs")
}

enum ProviderType {
    OPENAI
    OPENAI_COMPATIBLE
}

enum ModelCapability {
    SPEECH_TO_TEXT
    ROUTING
    REFLECTION
    IMAGE_GENERATION
    EMBEDDINGS
}
